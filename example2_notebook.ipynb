{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "# show pointclouds\n",
    "from open3d import *\n",
    "#  K = (0.89115971  0           0.5)\n",
    "#      (0           1.18821287  0.5)\n",
    "#      (0           0           1  ),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch import Tensor\n",
    "\n",
    "from depthNet_model import depthNet\n",
    "from visualize import *\n",
    "\n",
    "\n",
    "# model\n",
    "depthnet = depthNet()\n",
    "model_data = torch.load('opensource_model.pth.tar')\n",
    "depthnet.load_state_dict(model_data['state_dict'])\n",
    "depthnet = depthnet.cuda()\n",
    "cudnn.benchmark = True\n",
    "depthnet.eval()\n",
    "# for warp the image to construct the cost volume\n",
    "pixel_coordinate = np.indices([320, 256]).astype(np.float32)\n",
    "pixel_coordinate = np.concatenate(\n",
    "    (pixel_coordinate, np.ones([1, 320, 256])), axis=0)\n",
    "pixel_coordinate = np.reshape(pixel_coordinate, [3, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# imageio.plugins.freeimage.download()\n",
    "# from imageio.plugins import freeimage\n",
    "import json\n",
    "import cv2\n",
    "import sys\n",
    "sys.path.insert(-1, '../DeepNotebook/utils/')\n",
    "from transformations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = '/home/komatsu/datasets/demon/traindata/'\n",
    "# ROOT = '/home/komatsu/datasets/demon/testdata/'\n",
    "\n",
    "# dataset = 'mvs_achteck_turm'\n",
    "# dataset = 'mvs_breisach'\n",
    "# dataset = 'mvs_citywall'\n",
    "dataset = 'sun3d_train_0.01m_to_0.1m'\n",
    "# dataset = 'sun3d_train_0.2m_to_0.4m'\n",
    "# dataset = 'rgbd_10_to_20_3d_train'\n",
    "# dataset = 'rgbd_10_to_20_simple_train'\n",
    "# dataset = 'sun3d_test'\n",
    "\n",
    "with open(os.path.join(ROOT, dataset, \"num_images.json\")) as f:\n",
    "    num_images = json.load(f)\n",
    "print(len(num_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFrame(scene, idx):\n",
    "    fname = os.path.join(ROOT,dataset,'{:04d}/images/{:04}.png'.format(scene, idx))\n",
    "    img = imageio.imread(fname)\n",
    "    fname = os.path.join(ROOT,dataset,'{:04d}/depths/{:04}.exr'.format(scene, idx))\n",
    "    depth = imageio.imread(fname)\n",
    "    fname = os.path.join(ROOT,dataset,'{:04d}/poses/{:04}.json'.format(scene, idx))\n",
    "    with open(fname) as f:\n",
    "        cam = json.load(f)\n",
    "    return img, depth, cam\n",
    "\n",
    "def getPCD(img, depth, cam):\n",
    "    height, width, _ = img.shape\n",
    "    cam_o3 = PinholeCameraIntrinsic(width, height, cam['f_x'], cam['f_y'], cam['c_x'], cam['c_y'])\n",
    "    rgbd_image = create_rgbd_image_from_color_and_depth(\n",
    "        Image(img), Image(depth), depth_scale=1.0, depth_trunc=100, convert_rgb_to_intensity=False)\n",
    "    pcd = create_point_cloud_from_rgbd_image(rgbd_image, cam_o3)\n",
    "    # Flip it, otherwise the pointcloud will be upside down\n",
    "#     pcd.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "    return pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scene = 100\n",
    "left_image, left_depth, left_cam = getFrame(scene, 0)\n",
    "right_image, right_depth, right_cam = getFrame(scene, 1)\n",
    "fig, ax = plt.subplots(1,3)\n",
    "ax[0].imshow(left_image)\n",
    "ax[1].imshow(right_image)\n",
    "ax[2].imshow(left_depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = getPCD(left_image, left_depth, left_cam)\n",
    "pcd.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_pose = inv(left_cam['extrinsic'])\n",
    "right_pose = inv(right_cam['extrinsic'])\n",
    "\n",
    "fx = left_cam['f_x']\n",
    "fy = left_cam['f_y']\n",
    "cx = left_cam['c_x']\n",
    "cy = left_cam['c_y']\n",
    "camera_k = np.asarray([\n",
    "    [fx, 0, cx], \n",
    "    [0, fy, cy], \n",
    "    [0, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_image = cv2.cvtColor(right_image, cv2.COLOR_RGB2BGR)\n",
    "left_image = cv2.cvtColor(left_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# test the epipolar line\n",
    "left2right = np.dot(inv(right_pose), left_pose)\n",
    "test_point = np.asarray([left_image.shape[1] // 2, left_image.shape[0] // 2, 1])\n",
    "far_point = np.dot(inv(camera_k), test_point) * 50.0\n",
    "far_point = np.append(far_point, 1)\n",
    "far_point = np.dot(left2right, far_point)\n",
    "far_pixel = np.dot(camera_k, far_point[0:3])\n",
    "far_pixel = (far_pixel // far_pixel[2])[0:2]\n",
    "near_point = np.dot(inv(camera_k), test_point) * 0.1\n",
    "near_point = np.append(near_point, 1)\n",
    "near_point = np.dot(left2right, near_point)\n",
    "near_pixel = np.dot(camera_k, near_point[0:3])\n",
    "near_pixel = (near_pixel // near_pixel[2])[0:2]\n",
    "cv2.line(right_image, \n",
    "        (int(far_pixel[0] + 0.5), int(far_pixel[1] + 0.5)),\n",
    "        (int(near_pixel[0] + 0.5), int(near_pixel[1] + 0.5)), [0,0,255], 4)\n",
    "cv2.circle(left_image,(test_point[0], test_point[1]), 4, [0,0,255], -1)\n",
    "\n",
    "# cuda\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# scale to 320x256\n",
    "original_width = left_image.shape[1]\n",
    "original_height = left_image.shape[0]\n",
    "factor_x = 320.0 / original_width\n",
    "factor_y = 256.0 / original_height\n",
    "\n",
    "left_image = cv2.resize(left_image, (320, 256))\n",
    "right_image = cv2.resize(right_image, (320, 256))\n",
    "camera_k[0, :] *= factor_x\n",
    "camera_k[1, :] *= factor_y\n",
    "\n",
    "# convert to pythorch format\n",
    "torch_left_image = np.moveaxis(left_image, -1, 0)\n",
    "torch_left_image = np.expand_dims(torch_left_image, 0)\n",
    "torch_left_image = (torch_left_image - 81.0)/ 35.0\n",
    "torch_right_image = np.moveaxis(right_image, -1, 0)\n",
    "torch_right_image = np.expand_dims(torch_right_image, 0)\n",
    "torch_right_image = (torch_right_image - 81.0) / 35.0\n",
    "\n",
    "# process\n",
    "left_image_cuda = Tensor(torch_left_image).to(device)\n",
    "right_image_cuda = Tensor(torch_right_image).to(device)\n",
    "\n",
    "\n",
    "left_in_right_T = left2right[0:3, 3]\n",
    "left_in_right_R = left2right[0:3, 0:3]\n",
    "K = camera_k\n",
    "K_inverse = inv(K)\n",
    "KRK_i = K.dot(left_in_right_R.dot(K_inverse))\n",
    "KRKiUV = KRK_i.dot(pixel_coordinate)\n",
    "KT = K.dot(left_in_right_T)\n",
    "KT = np.expand_dims(KT, -1)\n",
    "KT = np.expand_dims(KT, 0)\n",
    "KT = KT.astype(np.float32)\n",
    "KRKiUV = KRKiUV.astype(np.float32)\n",
    "KRKiUV = np.expand_dims(KRKiUV, 0)\n",
    "KRKiUV_cuda_T = Tensor(KRKiUV).to(device)\n",
    "KT_cuda_T = Tensor(KT).to(device)\n",
    "\n",
    "predict_depths = depthnet(left_image_cuda, right_image_cuda, KRKiUV_cuda_T,\n",
    "                            KT_cuda_T)\n",
    "\n",
    "# visualize the results\n",
    "idepth = np.squeeze(predict_depths[0].cpu().data.numpy())\n",
    "np_depth = np2Depth(idepth, np.zeros(idepth.shape, dtype=bool))\n",
    "\n",
    "\n",
    "\n",
    "result_image = np.concatenate(\n",
    "    (left_image, right_image, np_depth), axis=1)\n",
    "cv2.imshow(\"result\", result_image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "\n",
    "width, height, _ = left_image.shape\n",
    "fx = 1.0\n",
    "fy = 1.0\n",
    "cx = 0.5\n",
    "cy = 0.5\n",
    "cam_o3 = PinholeCameraIntrinsic(width, height, fx*width, fy*height, cx*width, cy*height)\n",
    "cam_o3.intrinsic_matrix = K\n",
    "\n",
    "depth = 1/idepth\n",
    "left = left_image[:,:,::-1].copy()\n",
    "rgbd_image = create_rgbd_image_from_color_and_depth(\n",
    "    Image(left), Image(depth), depth_scale=1.0, depth_trunc=30, convert_rgb_to_intensity=False)\n",
    "pcd = create_point_cloud_from_rgbd_image(rgbd_image, cam_o3)\n",
    "pcd.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "draw_geometries([pcd])\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
